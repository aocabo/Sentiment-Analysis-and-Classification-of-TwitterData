{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text-mining-v4.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmCteSzJG2Xq"
      },
      "source": [
        "# Sentiment Analysis and Classification of Twitter Data (ResNet and LSTM)\r\n",
        "Andrés Ocabo (andoc277)\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Yr5b1JAHIra"
      },
      "source": [
        "# Read the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVDjKH5XtPoF",
        "outputId": "28d5a7e6-79a2-4f2d-96eb-058a70a6f31f"
      },
      "source": [
        "! unzip drive/MyDrive/project_text/data2.zip #Unzip the file"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  drive/MyDrive/project_text/data2.zip\n",
            "  inflating: Reddit_Data.csv         \n",
            "  inflating: Twitter_Data.csv        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "XQdOAhrLtSH0",
        "outputId": "ef454336-6e44-41fc-b4bd-aa812093f69f"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import csv\r\n",
        "\r\n",
        "df = pd.read_csv('Twitter_Data.csv')\r\n",
        "\r\n",
        "#This line is for using the Reddit data file\r\n",
        "#df = df.rename(columns = {'clean_comment': 'clean_text'}, inplace = False)\r\n",
        "\r\n",
        "#Remove all samples with null in class or document\r\n",
        "df = df[pd.notnull(df.clean_text) & pd.notnull(df.category)]\r\n",
        "\r\n",
        "#Show the first rows of the data frame\r\n",
        "df.head()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>when modi promised “minimum government maximum...</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>talk all the nonsense and continue all the dra...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>asking his supporters prefix chowkidar their n...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>answer who among these the most powerful world...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          clean_text  category\n",
              "0  when modi promised “minimum government maximum...      -1.0\n",
              "1  talk all the nonsense and continue all the dra...       0.0\n",
              "2  what did just say vote for modi  welcome bjp t...       1.0\n",
              "3  asking his supporters prefix chowkidar their n...       1.0\n",
              "4  answer who among these the most powerful world...       1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spKAvVFFYikh"
      },
      "source": [
        "## Text processing\r\n",
        "Here, the dataset is divided anf the k-fold manager funtion too. Also here we have the 3 different processing of the data for extracting the features that will be used during the training and testing the models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUK_fCcHX7hr"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.model_selection import KFold\r\n",
        "\r\n",
        "seed = 4321\r\n",
        "x_train_data, x_test_data, y_train, y_test = train_test_split(df['clean_text'],df['category'],test_size=0.25, \r\n",
        "                                                    random_state = seed)\r\n",
        "x_train_data = x_train_data.reset_index()['clean_text']\r\n",
        "x_test_data = x_test_data.reset_index()['clean_text']\r\n",
        "y_train = y_train.reset_index()['category']\r\n",
        "y_test = y_test.reset_index()['category']\r\n",
        "\r\n",
        "k = 5\r\n",
        "kfold = KFold(n_splits=k, shuffle = True, random_state = seed)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fG6fggrWYaeh"
      },
      "source": [
        "### Processing with Keras\r\n",
        "text_to_sequence: https://www.kdnuggets.com/2020/03/tensorflow-keras-tokenization-text-data-prep.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Uju6ZPg-Ycz",
        "outputId": "f4b7348c-eaf8-497e-d7d7-92904ca56459"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "\r\n",
        "max_fatures = 1000\r\n",
        "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\r\n",
        "tokenizer.fit_on_texts(x_train_data.values)\r\n",
        "\r\n",
        "X1_train = tokenizer.texts_to_sequences(x_train_data.values)\r\n",
        "#X1_train = tokenizer.texts_to_matrix(x_train_data.values, mode = 'tfidf')\r\n",
        "#print(type(X1_train))\r\n",
        "X1_test = tokenizer.texts_to_sequences(x_test_data.values)\r\n",
        "#X1_test = tokenizer.texts_to_matrix(x_test_data.values, mode = 'tfidf')\r\n",
        "\r\n",
        "\r\n",
        "n_test = len(X1_test)\r\n",
        "n_train = len(X1_train)\r\n",
        "X = X1_train + X1_test\r\n",
        "\r\n",
        "X = pad_sequences(X)\r\n",
        "x_train = X[:n_train,:]\r\n",
        "x_test = X[-n_test:,:]\r\n",
        "\r\n",
        "#x_train = pad_sequences(X1_train)\r\n",
        "#x_test = pad_sequences(X1_test)\r\n",
        "y_train = pd.get_dummies(y_train).values\r\n",
        "y_test = pd.get_dummies(y_test).values\r\n",
        "print(x_train.shape,y_train.shape)\r\n",
        "print(x_test.shape,y_test.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(122226, 47) (122226, 3)\n",
            "(40743, 47) (40743, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsIfmBIyZqrK"
      },
      "source": [
        "### Processing with Sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a2jxyc_aTS4",
        "outputId": "c60c86a4-1439-42b4-f9d4-7eab40c1c705"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bOqYksMaLR5"
      },
      "source": [
        "import spacy\r\n",
        "from nltk.corpus import stopwords\r\n",
        "# The data in english is loaded and \"tagger, \"parser\", \"ner\" and \"textcat\" are removed from the pipeline.\r\n",
        "nlp = spacy.load(\"en_core_web_sm\", disable=[\"tagger\", \"parser\", \"ner\",\"textcat\"])\r\n",
        "stop_words = stopwords.words('english')\r\n",
        "#Preprocess function is defined\r\n",
        "def preprocess(text):\r\n",
        "    doc = nlp(text)\r\n",
        "    out = [word.lemma_ for word in doc if not(word.lemma_ in stop_words) and nlp(word.lemma_)[0].is_alpha]\r\n",
        "    #out = [word.lemma_ for word in doc if not(word.is_stop) and nlp(word.lemma_)[0].is_alpha]\r\n",
        "    #out = [word.lemma_ for word in doc if nlp(word.lemma_)[0].is_alpha]\r\n",
        "    #out = [word.lower_ for word in doc]\r\n",
        "    \r\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjlQmHhrZxCS"
      },
      "source": [
        "#### Tfidf-vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7P5-mOPYZ1-y",
        "outputId": "d6c777c3-bd4d-4a58-eea7-29dcf11c4aea"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "\r\n",
        "vectorizer = TfidfVectorizer(tokenizer = preprocess, max_features = 1000, ngram_range = (1,2))\r\n",
        "x_train = vectorizer.fit_transform(x_train_data) #It takes less than 1 min\r\n",
        "x_test = vectorizer.transform(x_test_data) # It takes less than 30 sec\r\n",
        "\r\n",
        "x_train = x_train.toarray()\r\n",
        "x_test = x_test.toarray()\r\n",
        "y_train = pd.get_dummies(y_train).values\r\n",
        "y_test = pd.get_dummies(y_test).values\r\n",
        "\r\n",
        "print(x_train.shape,y_train.shape)\r\n",
        "print(x_test.shape,y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(122226, 1000) (122226, 3)\n",
            "(40743, 1000) (40743, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVY_9emeZ6Hn"
      },
      "source": [
        "#### Count-vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-4q1CR6Z5cZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83a6992c-8fca-4df9-ca27-67e24ac4d3d5"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "\r\n",
        "vectorizer = CountVectorizer(tokenizer = preprocess, max_features = 1000, ngram_range = (1,2))\r\n",
        "x_train = vectorizer.fit_transform(x_train_data) #It takes less than 1 min\r\n",
        "x_test = vectorizer.transform(x_test_data) # It takes less than 30 sec\r\n",
        "\r\n",
        "x_train = x_train.toarray()\r\n",
        "x_test = x_test.toarray()\r\n",
        "y_train = pd.get_dummies(y_train).values\r\n",
        "y_test = pd.get_dummies(y_test).values\r\n",
        "\r\n",
        "print(x_train.shape,y_train.shape)\r\n",
        "print(x_test.shape,y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(122226, 1000) (122226, 3)\n",
            "(40743, 1000) (40743, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FV_0avK3HT9c"
      },
      "source": [
        "# Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4mssrdFbGmf"
      },
      "source": [
        "# Class defined to save and show the results during the k-fold cross validation\r\n",
        "class Results:\r\n",
        "    def __init__(self, k):\r\n",
        "        self.results = {'Negative':{'precision': 0, 'recall': 0, 'f1-score': 0},\r\n",
        "           'Neutral':{'precision': 0, 'recall': 0, 'f1-score': 0},\r\n",
        "           'Positive':{'precision': 0, 'recall': 0, 'f1-score': 0},\r\n",
        "           'Accuracy':0\r\n",
        "          }\r\n",
        "        self.k = k\r\n",
        "    def save(self, report):\r\n",
        "        #Calculation and esults\r\n",
        "        self.results['Negative']['precision'] = self.results['Negative']['precision'] + report['0']['precision']/self.k\r\n",
        "        self.results['Neutral']['precision'] = self.results['Neutral']['precision'] + report['1']['precision']/self.k\r\n",
        "        self.results['Positive']['precision'] = self.results['Positive']['precision'] + report['2']['precision']/self.k\r\n",
        "\r\n",
        "        self.results['Negative']['recall'] = self.results['Negative']['recall'] + report['0']['recall']/self.k\r\n",
        "        self.results['Neutral']['recall'] = self.results['Neutral']['recall'] + report['1']['recall']/self.k\r\n",
        "        self.results['Positive']['recall'] = self.results['Positive']['recall'] + report['2']['recall']/self.k\r\n",
        "\r\n",
        "        self.results['Negative']['f1-score'] = self.results['Negative']['f1-score'] + report['0']['f1-score']/self.k\r\n",
        "        self.results['Neutral']['f1-score'] = self.results['Neutral']['f1-score'] + report['1']['f1-score']/self.k\r\n",
        "        self.results['Positive']['f1-score'] = self.results['Positive']['f1-score'] + report['2']['f1-score']/self.k\r\n",
        "\r\n",
        "        self.results['Accuracy'] = self.results['Accuracy'] + report['accuracy']/self.k\r\n",
        "        \r\n",
        "        return self.results\r\n",
        "    \r\n",
        "    def show(self):\r\n",
        "        import pprint\r\n",
        "        pprint.pprint(self.results)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KntY8_8_bHDo"
      },
      "source": [
        "## LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbV4UZcNbCWv"
      },
      "source": [
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Embedding, LSTM\r\n",
        "\r\n",
        "def get_lstm(input_len, show = False):\r\n",
        "  embed_dim = 150\r\n",
        "  lstm_out = 200\r\n",
        "  max_fatures = 1000\r\n",
        "  model = Sequential()\r\n",
        "  model.add(Embedding(max_fatures, embed_dim,input_length = input_len))\r\n",
        "  model.add(LSTM(lstm_out, dropout=0.2))\r\n",
        "  model.add(Dense(3,activation='softmax'))\r\n",
        "  model.compile(loss = 'categorical_crossentropy', optimizer='nadam',metrics = ['accuracy'])\r\n",
        "  if show:\r\n",
        "    print(model.summary())\r\n",
        "  return model\r\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARFSHLnQBWV9",
        "outputId": "1bb4a26a-4511-4af3-8f6c-c0c57fb43766"
      },
      "source": [
        "# Plotting a summary of the model\r\n",
        "model = get_lstm(input_len = x_train.shape[1], show = True)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 47, 150)           150000    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 200)               280800    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3)                 603       \n",
            "=================================================================\n",
            "Total params: 431,403\n",
            "Trainable params: 431,403\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSZBQdpVehuh",
        "outputId": "6a2fd06d-c216-4daa-8b63-ed6a9be678c1"
      },
      "source": [
        "from sklearn.metrics import classification_report\r\n",
        "results = Results(k)\r\n",
        "i = 0\r\n",
        "for train, val in kfold.split(x_train):\r\n",
        "  i = i + 1\r\n",
        "  print('Fold ', i, '/', k)\r\n",
        "  X_train, Y_train = x_train[train], y_train[train]\r\n",
        "  X_val, Y_val = x_train[val], y_train[val]\r\n",
        "  \r\n",
        "    \r\n",
        "  model = get_lstm(input_len = X_train.shape[1])\r\n",
        "  batch_size = 32\r\n",
        "  print('Training')\r\n",
        "  model.fit(X_train, Y_train, epochs = 3, batch_size=batch_size, verbose = 1)\r\n",
        "  print('Validation')\r\n",
        "  Y_pred = model.predict_classes(X_val, verbose = 1)\r\n",
        "\r\n",
        "  Y_val = np.argmax(Y_val, axis=1)\r\n",
        "  report = classification_report(Y_val, Y_pred, output_dict= True)\r\n",
        "  results.save(report)\r\n",
        "results.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold  1 / 5\n",
            "Training\n",
            "Epoch 1/3\n",
            "3056/3056 [==============================] - 73s 22ms/step - loss: 0.6331 - accuracy: 0.7511\n",
            "Epoch 2/3\n",
            "3056/3056 [==============================] - 66s 22ms/step - loss: 0.4657 - accuracy: 0.8392\n",
            "Epoch 3/3\n",
            "3056/3056 [==============================] - 66s 21ms/step - loss: 0.4542 - accuracy: 0.8403\n",
            "Validation\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "764/764 [==============================] - 5s 6ms/step\n",
            "Fold  2 / 5\n",
            "Training\n",
            "Epoch 1/3\n",
            "3056/3056 [==============================] - 70s 22ms/step - loss: 0.6283 - accuracy: 0.7514\n",
            "Epoch 2/3\n",
            "3056/3056 [==============================] - 67s 22ms/step - loss: 0.4755 - accuracy: 0.8341\n",
            "Epoch 3/3\n",
            "3056/3056 [==============================] - 67s 22ms/step - loss: 0.4538 - accuracy: 0.8407\n",
            "Validation\n",
            "764/764 [==============================] - 5s 6ms/step\n",
            "Fold  3 / 5\n",
            "Training\n",
            "Epoch 1/3\n",
            "3056/3056 [==============================] - 68s 21ms/step - loss: 0.6243 - accuracy: 0.7556\n",
            "Epoch 2/3\n",
            "3056/3056 [==============================] - 66s 21ms/step - loss: 0.4725 - accuracy: 0.8348\n",
            "Epoch 3/3\n",
            "3056/3056 [==============================] - 65s 21ms/step - loss: 0.4572 - accuracy: 0.8383\n",
            "Validation\n",
            "764/764 [==============================] - 5s 6ms/step\n",
            "Fold  4 / 5\n",
            "Training\n",
            "Epoch 1/3\n",
            "3056/3056 [==============================] - 69s 22ms/step - loss: 0.6235 - accuracy: 0.7556\n",
            "Epoch 2/3\n",
            "3056/3056 [==============================] - 67s 22ms/step - loss: 0.4711 - accuracy: 0.8362\n",
            "Epoch 3/3\n",
            "3056/3056 [==============================] - 67s 22ms/step - loss: 0.4547 - accuracy: 0.8401\n",
            "Validation\n",
            "764/764 [==============================] - 5s 6ms/step\n",
            "Fold  5 / 5\n",
            "Training\n",
            "Epoch 1/3\n",
            "3056/3056 [==============================] - 69s 22ms/step - loss: 0.6357 - accuracy: 0.7470\n",
            "Epoch 2/3\n",
            "3056/3056 [==============================] - 66s 22ms/step - loss: 0.4742 - accuracy: 0.8353\n",
            "Epoch 3/3\n",
            "3056/3056 [==============================] - 66s 22ms/step - loss: 0.4557 - accuracy: 0.8386\n",
            "Validation\n",
            "764/764 [==============================] - 5s 6ms/step\n",
            "{'Accuracy': 0.8399931239616182,\n",
            " 'Negative': {'f1-score': 0.7331127416913231,\n",
            "              'precision': 0.8685614297279498,\n",
            "              'recall': 0.6343457982124983},\n",
            " 'Neutral': {'f1-score': 0.8548322198785359,\n",
            "             'precision': 0.7582181261267271,\n",
            "             'recall': 0.9797135641738867},\n",
            " 'Positive': {'f1-score': 0.8737140313411055,\n",
            "              'precision': 0.9181581025336456,\n",
            "              'recall': 0.8334397226283516}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-f8MXSR0k91",
        "outputId": "1c318653-8244-4540-c3de-1f5c2b5ce98d"
      },
      "source": [
        "batch_size = 32\r\n",
        "model = get_lstm(input_len = X_train.shape[1], show = False)\r\n",
        "model.fit(x_train, y_train, epochs = 3, batch_size=batch_size, verbose = 1)\r\n",
        "\r\n",
        "print('TRAIN RESULTS:')\r\n",
        "results = Results(1)\r\n",
        "y_pred = model.predict_classes(x_train, verbose = 1)\r\n",
        "y_train = np.argmax(y_train, axis=1)\r\n",
        "report = classification_report(y_train, y_pred, output_dict= True)\r\n",
        "results.save(report)\r\n",
        "results.show()\r\n",
        "\r\n",
        "print('TEST RESULTS:')\r\n",
        "results = Results(1)\r\n",
        "y_pred = model.predict_classes(x_test, verbose = 1)\r\n",
        "y_test = np.argmax(y_test, axis=1)\r\n",
        "report = classification_report(y_test, y_pred, output_dict= True)\r\n",
        "results.save(report)\r\n",
        "results.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "3820/3820 [==============================] - 85s 22ms/step - loss: 0.6161 - accuracy: 0.7608\n",
            "Epoch 2/3\n",
            "3820/3820 [==============================] - 83s 22ms/step - loss: 0.4693 - accuracy: 0.8366\n",
            "Epoch 3/3\n",
            "3820/3820 [==============================] - 83s 22ms/step - loss: 0.4513 - accuracy: 0.8417\n",
            "TRAIN RESULTS:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "3820/3820 [==============================] - 22s 6ms/step\n",
            "{'Accuracy': 0.8440675470030926,\n",
            " 'Negative': {'f1-score': 0.7446734799930712,\n",
            "              'precision': 0.8740469655382739,\n",
            "              'recall': 0.6486608826857789},\n",
            " 'Neutral': {'f1-score': 0.8562692412406543,\n",
            "             'precision': 0.7578639085061818,\n",
            "             'recall': 0.9840429372548076},\n",
            " 'Positive': {'f1-score': 0.8773961272744966,\n",
            "              'precision': 0.9276176367713928,\n",
            "              'recall': 0.8323333394871416}}\n",
            "TEST RESULTS:\n",
            "1274/1274 [==============================] - 7s 6ms/step\n",
            "{'Accuracy': 0.8372726603342906,\n",
            " 'Negative': {'f1-score': 0.7373460139145976,\n",
            "              'precision': 0.8662267546490702,\n",
            "              'recall': 0.641849094343816},\n",
            " 'Neutral': {'f1-score': 0.8497222923504166,\n",
            "             'precision': 0.7468656385221347,\n",
            "             'recall': 0.985434050651442},\n",
            " 'Positive': {'f1-score': 0.8715830183703964,\n",
            "              'precision': 0.9267867156832201,\n",
            "              'recall': 0.8225859971242119}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKreGSiHvjDi"
      },
      "source": [
        "## ResNet\r\n",
        "explicacion resnet: https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGc6t4D8vie7"
      },
      "source": [
        "from keras.layers import Input, Conv1D, Activation, BatchNormalization, GlobalAveragePooling1D, Dense, Dropout, MaxPool1D\r\n",
        "from keras.layers.merge import add\r\n",
        "from keras.activations import relu, softmax\r\n",
        "from keras.models import Model\r\n",
        "from keras import regularizers\r\n",
        "\r\n",
        "\r\n",
        "def block(n_output, upscale=False):\r\n",
        "    # n_output: number of feature maps in the block\r\n",
        "    # upscale: should we use the 1x1 conv2d mapping for shortcut or not\r\n",
        "    \r\n",
        "    # keras functional api: return the function of type\r\n",
        "    # Tensor -> Tensor\r\n",
        "    def f(x):\r\n",
        "        \r\n",
        "        \r\n",
        "        # first convolution\r\n",
        "        h = Conv1D(kernel_size=3, filters=n_output, strides=1, padding='same', kernel_regularizer=regularizers.l2(0.01))(x)\r\n",
        "        h = BatchNormalization()(h)\r\n",
        "        h = Activation(softmax)(h)\r\n",
        "        \r\n",
        "        # second convolution\r\n",
        "        h = Conv1D(kernel_size=3, filters=n_output, strides=1, padding='same', kernel_regularizer=regularizers.l2(0.01))(h)\r\n",
        "        h = BatchNormalization()(h)\r\n",
        "        h = Activation(softmax)(h)\r\n",
        "        #f = Conv1D(kernel_size=1, filters=n_output, strides=1, padding='same')(x)\r\n",
        "        # f(x):\r\n",
        "        if upscale:\r\n",
        "            # 1x1 conv1d\r\n",
        "            f = Conv1D(kernel_size=1, filters=n_output, strides=1, padding='same')(x)\r\n",
        "        else:\r\n",
        "            # identity\r\n",
        "            f = x\r\n",
        "        \r\n",
        "        return add([f, h])\r\n",
        "    \r\n",
        "    return f\r\n",
        "\r\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWEy2LnYwN65"
      },
      "source": [
        "def get_ResNet(input_len, show = False):\r\n",
        "  input_tensor = Input((input_len, 1))\r\n",
        "  x = Conv1D(kernel_size=7, filters=32, strides=1, padding='same', kernel_regularizer=regularizers.l2(0.01))(input_tensor)\r\n",
        "  x = MaxPool1D(pool_size=2)(x)\r\n",
        "  x = block(32)(x)\r\n",
        "  x = block(32)(x)\r\n",
        "  x = block(32)(x)\r\n",
        "  x = block(64, upscale=True)(x)\r\n",
        "  x = block(64)(x)\r\n",
        "  x = block(64)(x)\r\n",
        "  x = block(128, upscale=True)(x)\r\n",
        "  x = block(128)(x)\r\n",
        "  x = block(128)(x)\r\n",
        "  x = block(512, upscale=True)(x)\r\n",
        "  x = block(512)(x)\r\n",
        "  x = GlobalAveragePooling1D()(x)\r\n",
        "  x = Dropout(0.2)(x)\r\n",
        "  x = Dense(3)(x)\r\n",
        "  x = Activation(softmax)(x)\r\n",
        "  model = Model(inputs=input_tensor, outputs=x)\r\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='nadam', metrics=['accuracy'])\r\n",
        "  if show:\r\n",
        "    print(model.summary())\r\n",
        "  return model\r\n",
        "\r\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7ZUulCVwYVG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d38de74c-560b-4b1b-aea1-f69b906907e8"
      },
      "source": [
        "model = get_ResNet(x_train.shape[1], show=True)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 47, 1)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_52 (Conv1D)              (None, 47, 32)       256         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1D)  (None, 23, 32)       0           conv1d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_53 (Conv1D)              (None, 23, 32)       3104        max_pooling1d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 23, 32)       128         conv1d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 23, 32)       0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_54 (Conv1D)              (None, 23, 32)       3104        activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 23, 32)       128         conv1d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 23, 32)       0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, 23, 32)       0           max_pooling1d_2[0][0]            \n",
            "                                                                 activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_55 (Conv1D)              (None, 23, 32)       3104        add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 23, 32)       128         conv1d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 23, 32)       0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_56 (Conv1D)              (None, 23, 32)       3104        activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 23, 32)       128         conv1d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 23, 32)       0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, 23, 32)       0           add_22[0][0]                     \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_57 (Conv1D)              (None, 23, 32)       3104        add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 23, 32)       128         conv1d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 23, 32)       0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_58 (Conv1D)              (None, 23, 32)       3104        activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 23, 32)       128         conv1d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 23, 32)       0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, 23, 32)       0           add_23[0][0]                     \n",
            "                                                                 activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_59 (Conv1D)              (None, 23, 64)       6208        add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 23, 64)       256         conv1d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 23, 64)       0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_60 (Conv1D)              (None, 23, 64)       12352       activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 23, 64)       256         conv1d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_61 (Conv1D)              (None, 23, 64)       2112        add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 23, 64)       0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, 23, 64)       0           conv1d_61[0][0]                  \n",
            "                                                                 activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_62 (Conv1D)              (None, 23, 64)       12352       add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 23, 64)       256         conv1d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 23, 64)       0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_63 (Conv1D)              (None, 23, 64)       12352       activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 23, 64)       256         conv1d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 23, 64)       0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, 23, 64)       0           add_25[0][0]                     \n",
            "                                                                 activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_64 (Conv1D)              (None, 23, 64)       12352       add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 23, 64)       256         conv1d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 23, 64)       0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_65 (Conv1D)              (None, 23, 64)       12352       activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 23, 64)       256         conv1d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 23, 64)       0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, 23, 64)       0           add_26[0][0]                     \n",
            "                                                                 activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_66 (Conv1D)              (None, 23, 128)      24704       add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 23, 128)      512         conv1d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 23, 128)      0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_67 (Conv1D)              (None, 23, 128)      49280       activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 23, 128)      512         conv1d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_68 (Conv1D)              (None, 23, 128)      8320        add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 23, 128)      0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, 23, 128)      0           conv1d_68[0][0]                  \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_69 (Conv1D)              (None, 23, 128)      49280       add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 23, 128)      512         conv1d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 23, 128)      0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_70 (Conv1D)              (None, 23, 128)      49280       activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 23, 128)      512         conv1d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 23, 128)      0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, 23, 128)      0           add_28[0][0]                     \n",
            "                                                                 activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_71 (Conv1D)              (None, 23, 128)      49280       add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 23, 128)      512         conv1d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 23, 128)      0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_72 (Conv1D)              (None, 23, 128)      49280       activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 23, 128)      512         conv1d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 23, 128)      0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, 23, 128)      0           add_29[0][0]                     \n",
            "                                                                 activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_73 (Conv1D)              (None, 23, 512)      197120      add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 23, 512)      2048        conv1d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 23, 512)      0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_74 (Conv1D)              (None, 23, 512)      786944      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 23, 512)      2048        conv1d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_75 (Conv1D)              (None, 23, 512)      66048       add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 23, 512)      0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, 23, 512)      0           conv1d_75[0][0]                  \n",
            "                                                                 activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_76 (Conv1D)              (None, 23, 512)      786944      add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 23, 512)      2048        conv1d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 23, 512)      0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_77 (Conv1D)              (None, 23, 512)      786944      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 23, 512)      2048        conv1d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 23, 512)      0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_32 (Add)                    (None, 23, 512)      0           add_31[0][0]                     \n",
            "                                                                 activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling1d_2 (Glo (None, 512)          0           add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 512)          0           global_average_pooling1d_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 3)            1539        dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 3)            0           dense_9[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 3,007,491\n",
            "Trainable params: 3,000,707\n",
            "Non-trainable params: 6,784\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6p-nQr3rdGL",
        "outputId": "0c3b042e-6294-4834-9ca0-4d9c42facf82"
      },
      "source": [
        "results = Results(k)\r\n",
        "i = 0\r\n",
        "for train, val in kfold.split(x_train):\r\n",
        "  i = i + 1\r\n",
        "  print('Fold ', i, '/', k)\r\n",
        "  X_train, Y_train = x_train[train], y_train[train]\r\n",
        "  X_val, Y_val = x_train[val], y_train[val]\r\n",
        "  \r\n",
        "  model = get_ResNet(X_train.shape[1])\r\n",
        "  batch_size = 32\r\n",
        "  model.fit(X_train[:,:,np.newaxis], Y_train, epochs = 3, batch_size=batch_size, verbose = 1)\r\n",
        "  Y_pred = model.predict(X_val[:,:,np.newaxis], verbose = 1)\r\n",
        "\r\n",
        "  Y_pred = Y_pred.argmax(axis = 1)\r\n",
        "  Y_val = Y_val.argmax(axis = 1)\r\n",
        "  report = classification_report(Y_val, Y_pred, output_dict= True)\r\n",
        "  results.save(report)\r\n",
        "results.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fold  1 / 5\n",
            "Epoch 1/3\n",
            "3056/3056 [==============================] - 207s 63ms/step - loss: 2.8007 - accuracy: 0.4667\n",
            "Epoch 2/3\n",
            "3056/3056 [==============================] - 191s 63ms/step - loss: 1.0084 - accuracy: 0.5145\n",
            "Epoch 3/3\n",
            "3056/3056 [==============================] - 192s 63ms/step - loss: 1.0001 - accuracy: 0.5191\n",
            "764/764 [==============================] - 8s 10ms/step\n",
            "Fold  2 / 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "3056/3056 [==============================] - 206s 63ms/step - loss: 2.8935 - accuracy: 0.4675\n",
            "Epoch 2/3\n",
            "3056/3056 [==============================] - 190s 62ms/step - loss: 1.0147 - accuracy: 0.5095\n",
            "Epoch 3/3\n",
            "3056/3056 [==============================] - 191s 62ms/step - loss: 1.0024 - accuracy: 0.5180\n",
            "764/764 [==============================] - 8s 10ms/step\n",
            "Fold  3 / 5\n",
            "Epoch 1/3\n",
            "3056/3056 [==============================] - 205s 62ms/step - loss: 2.7798 - accuracy: 0.4693\n",
            "Epoch 2/3\n",
            "3056/3056 [==============================] - 194s 64ms/step - loss: 1.0089 - accuracy: 0.5119\n",
            "Epoch 3/3\n",
            "3056/3056 [==============================] - 200s 65ms/step - loss: 0.9987 - accuracy: 0.5205\n",
            "764/764 [==============================] - 8s 10ms/step\n",
            "Fold  4 / 5\n",
            "Epoch 1/3\n",
            "3056/3056 [==============================] - 216s 66ms/step - loss: 2.7068 - accuracy: 0.4687\n",
            "Epoch 2/3\n",
            "3056/3056 [==============================] - 200s 65ms/step - loss: 1.0107 - accuracy: 0.5092\n",
            "Epoch 3/3\n",
            "3056/3056 [==============================] - 202s 66ms/step - loss: 1.0007 - accuracy: 0.5166\n",
            "764/764 [==============================] - 8s 10ms/step\n",
            "Fold  5 / 5\n",
            "Epoch 1/3\n",
            "3056/3056 [==============================] - 215s 65ms/step - loss: 2.6552 - accuracy: 0.4668\n",
            "Epoch 2/3\n",
            "3056/3056 [==============================] - 198s 65ms/step - loss: 1.0099 - accuracy: 0.5130\n",
            "Epoch 3/3\n",
            "3056/3056 [==============================] - 197s 64ms/step - loss: 1.0032 - accuracy: 0.5174\n",
            "764/764 [==============================] - 8s 10ms/step\n",
            "{'Accuracy': 0.5208712216742235,\n",
            " 'Negative': {'f1-score': 0.0, 'precision': 0.0, 'recall': 0.0},\n",
            " 'Neutral': {'f1-score': 0.5724426058510513,\n",
            "             'precision': 0.5235517524896603,\n",
            "             'recall': 0.6326415476048377},\n",
            " 'Positive': {'f1-score': 0.5925520107880711,\n",
            "              'precision': 0.5194637039738093,\n",
            "              'recall': 0.6901617954598345}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4V7iBvSGg2w",
        "outputId": "d7d1813a-9697-4afe-d8b3-a743f456dcfc"
      },
      "source": [
        "from sklearn.metrics import classification_report\r\n",
        "report = classification_report(Y_val, Y_pred, output_dict= True)\r\n",
        "results.save(report)\r\n",
        "results.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Accuracy': 0.52163953202978,\n",
            " 'Negative': {'f1-score': 0.0, 'precision': 0.0, 'recall': 0.0},\n",
            " 'Neutral': {'f1-score': 0.5916855631141346,\n",
            "             'precision': 0.5064262917277668,\n",
            "             'recall': 0.711463887542414},\n",
            " 'Positive': {'f1-score': 0.5821981555123107,\n",
            "              'precision': 0.5353613942270287,\n",
            "              'recall': 0.638015762633287}}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4E-l_iG6waY2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f2f4837-a39b-42ab-85d8-250d6a0394f1"
      },
      "source": [
        "model = get_ResNet(x_train.shape[1])\r\n",
        "batch_size = 32\r\n",
        "model.fit(x_train[:,:,np.newaxis], y_train, epochs = 2, batch_size=batch_size, verbose = 1)\r\n",
        "\r\n",
        "print('TRAIN RESULTS:')\r\n",
        "results = Results(1)\r\n",
        "y_pred = model.predict(x_train[:,:,np.newaxis], verbose = 1)\r\n",
        "y_pred = y_pred.argmax(axis = 1)\r\n",
        "y_train = y_train.argmax(axis = 1)\r\n",
        "report = classification_report(y_train, y_pred, output_dict= True)\r\n",
        "results.save(report)\r\n",
        "results.show()\r\n",
        "\r\n",
        "\r\n",
        "print('TEST RESULTS:')\r\n",
        "results = Results(1)\r\n",
        "y_pred = model.predict(x_test[:,:,np.newaxis], verbose = 1)\r\n",
        "y_pred = y_pred.argmax(axis = 1)\r\n",
        "y_test = y_test.argmax(axis = 1)\r\n",
        "report = classification_report(y_test, y_pred, output_dict= True)\r\n",
        "results.save(report)\r\n",
        "results.show()\r\n",
        "\r\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "3820/3820 [==============================] - 261s 64ms/step - loss: 2.4473 - accuracy: 0.4774\n",
            "Epoch 2/2\n",
            "3820/3820 [==============================] - 243s 64ms/step - loss: 1.0042 - accuracy: 0.5172\n",
            "TRAIN RESULTS:\n",
            "3820/3820 [==============================] - 38s 10ms/step\n",
            "{'Accuracy': 0.5220329553450166,\n",
            " 'Negative': {'f1-score': 0.0, 'precision': 0.0, 'recall': 0.0},\n",
            " 'Neutral': {'f1-score': 0.5766834257230029,\n",
            "             'precision': 0.5208110992529349,\n",
            "             'recall': 0.6459842595489663},\n",
            " 'Positive': {'f1-score': 0.5921286581556648,\n",
            "              'precision': 0.5229237102318541,\n",
            "              'recall': 0.6824450311075009}}\n",
            "TEST RESULTS:\n",
            "   1/1274 [..............................] - ETA: 25s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1274/1274 [==============================] - 13s 10ms/step\n",
            "{'Accuracy': 0.5212183687995484,\n",
            " 'Negative': {'f1-score': 0.0, 'precision': 0.0, 'recall': 0.0},\n",
            " 'Neutral': {'f1-score': 0.5797214376156617,\n",
            "             'precision': 0.5209172063714336,\n",
            "             'recall': 0.6534914361001317},\n",
            " 'Positive': {'f1-score': 0.5905100033584416,\n",
            "              'precision': 0.5214370445687172,\n",
            "              'recall': 0.6806769162703241}}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}